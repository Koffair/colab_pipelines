{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Koffair/colab_pipelines/blob/main/notebooks/prepare_data.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# TODOs\n",
        "- miért kell a google acconut => ez adja a drive-ot és ezzel tudjuk használni a colabet\n",
        "\n",
        "\n",
        "The aim of this Notebook is to prepare the data for:\n",
        "- training a huggingsound model\n",
        "- training various output correction tools (e.g. an ngram language model) that\n",
        "will help us to increase the accuracy of our transcripts\n",
        "\n",
        "The magic will happen elswhere, here we just get some data and prepare them for further processing.\n",
        "\n",
        "# Data sources\n",
        " - [OSCAR 2019](https://oscar-project.org/post/oscar-2019/) Hungarian sub-corpus\n",
        " - [nyest.hu](https://www.nyest.hu/) a corpus containing all the articles from nyest (closed copyrighted material)\n",
        "\n",
        "## Prerequisites\n",
        "- a Google account\n",
        "- Colab Pro+ subscription, or any other cloud-based Jupyter Notebook support with a GPU, like Datalore, or a decent machine with a GPU\n",
        "- download the abovementioned datasets to your Google Drive\n",
        "\n",
        "## WARNINGS\n",
        "- If you are not familiar with Jupyter Notebooks, take some time to get used to id e.g. [this resource](https://www.manning.com/liveproject/getting-started-with-jupyter-notebook) explains the very basics of it\n",
        "- If you are new to Colab, take some time to familiarize yourself with it. You may find [this course](https://www.manning.com/liveproject/getting-started-with-Google-Colab-using-PyTorch) helpful.\n",
        "- You can run the cells of this notebook on Colab. Click on the \"Open in Colab\" badge at the top of the page.\n",
        "- Don't run this notebook! Click File > \"Save a Copy in Drive\" before you start working and you modify anything.\n",
        "- Check the path of your data. Probably you have to modify the path to the data files according to the folder structure of your Google Drive.\n",
        "\n",
        "## Uncompressing the data\n",
        "The following setps uncompress the data files in the appropriate directories.\n",
        "The original compressed files will be deleted!"
      ],
      "metadata": {
        "id": "69yWxW5nekiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to Google Drive"
      ],
      "metadata": {
        "id": "n4RTAdB4o79r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpTtRvrNo_zR",
        "outputId": "fc74495c-09d0-46fd-b4a4-afaf8bd82063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/My Drive/Colab Notebooks/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gahkra9jqf0T",
        "outputId": "276036b0-53b1-4337-c244-3f0eb3c3b582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpora  interim  mcc_langmods\tmodels\tprepare_data.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uncompress OSCAR txt files\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q01dXoN_2E0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd \"/content/gdrive/My Drive/Colab Notebooks/corpora/OSCAR2019_hu\"; gzip -d *.gz"
      ],
      "metadata": {
        "id": "pkbX_btC1QEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uncompress nyest corpus"
      ],
      "metadata": {
        "id": "5JOp9DAP7rpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd \"/content/gdrive/My Drive/Colab Notebooks/corpora/nyest\"; unzip contents.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpZLdz6F7vf6",
        "outputId": "fdb01115-aa64-413c-d91c-531f3ed2bac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  contents.zip\n",
            "  inflating: contents.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up text corpora\n"
      ],
      "metadata": {
        "id": "Cu2N0a3qy6Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting nltk punkt tokenizer\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BMIYgL-tmYT",
        "outputId": "423ad067-9d2f-4ca2-be0b-235da5732289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OSCAR 2019"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zKaRYjMIPoDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install blingfire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNoUvijlZmP0",
        "outputId": "7223c167-1b8d-4aac-e0d3-70b58fb08785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blingfire\n",
            "  Downloading blingfire-0.1.8-py3-none-any.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blingfire\n",
            "Successfully installed blingfire-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import concurrent.futures\n",
        "\n",
        "from blingfire import text_to_words\n",
        "\n",
        "data_root = \"/content/gdrive/My Drive/Colab Notebooks/corpora/OSCAR2019_hu\"\n",
        "text_files = [\n",
        "    e for e in os.listdir(data_root) if os.path.isfile(os.path.join(data_root, e))\n",
        "]\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Colab Notebooks/interim/oscar.txt\", \"w\") as outfile:\n",
        "  for text_file in text_files:\n",
        "    print(text_file)\n",
        "    with open(os.path.join(data_root, text_file), \"r\") as infile:\n",
        "      with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "        res = {executor.submit(text_to_words, line) for line in infile}\n",
        "        for future in concurrent.futures.as_completed(res):\n",
        "          data = future.result()\n",
        "          wds = data.split()\n",
        "          wds = [wd.lower() for wd in wds if wd.isalnum()]\n",
        "          wds = \" \".join(wds)\n",
        "          outfile.write(wds + \"\\n\")\n"
      ],
      "metadata": {
        "id": "6V6LuPMIs4AZ",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nyest.hu"
      ],
      "metadata": {
        "collapsed": false,
        "id": "CK1xt6NAPoDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import html\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data_root = \"/content/gdrive/My Drive/Colab Notebooks/corpora/nyest/contents.csv\"\n",
        "df = pd.read_csv(data_root, sep=\";\")\n",
        "df.fillna('', inplace=True)\n",
        "\n",
        "CLEANR = re.compile('<.*?>')\n",
        "CDATA = re.compile('\\/\\/\\s&lt;!\\[CDATA\\[\\n.*\\n\\/\\/\\s*\\]\\]&gt;')\n",
        "\n",
        "\n",
        "def clean_txt(txt):\n",
        "    \"\"\"Postprocess txt, removes unescaped html entities\"\"\"\n",
        "    txt = txt.replace(\"&amp;gt;\", \" \").replace(\"&amp;nbsp;\", \" \").replace(\"&quot;\", \" \")\n",
        "    txt = txt.replace(\"&#x27\", \" \").replace(\"::adbox::7::\", \"\").replace(\"&amp;lt;\", \" \")\n",
        "    txt = txt.replace(\"&amp;amp;\", \" \")\n",
        "    return txt\n",
        "\n",
        "\n",
        "def cleanhtml(raw_html):\n",
        "    \"\"\"Clean raw html page\"\"\"\n",
        "    cleaned_txt = clean_txt(html.escape(re.sub(CLEANR, ' ', raw_html)))\n",
        "    return re.sub(CDATA, ' ', cleaned_txt)\n",
        "\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Colab Notebooks/interim/nyest.txt\", \"w\") as outfile:\n",
        "    for _, row in df.iterrows():\n",
        "        title = cleanhtml(row[0])\n",
        "        lead = cleanhtml(row[3])\n",
        "        text = cleanhtml(row[4])\n",
        "        full_text = \" \".join([title, lead, text])\n",
        "        sentences = sent_tokenize(full_text)\n",
        "        for sentence in sentences:\n",
        "            if sentence:\n",
        "                words = word_tokenize(sentence)\n",
        "                words = [word.lower() for word in words if word.isalnum()]\n",
        "                if words:\n",
        "                    s = \" \".join(words)\n",
        "                    outfile.write(s + \"\\n\")"
      ],
      "metadata": {
        "id": "r3njm8WyPoDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenate corpora"
      ],
      "metadata": {
        "id": "jetVIyCrValm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd \"/content/gdrive/My Drive/Colab Notebooks/interim/\"; cat *.txt > merged_corpus.txt"
      ],
      "metadata": {
        "id": "IWl3OL3aVgOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "snkSxWGo7QSi"
      }
    }
  ]
}